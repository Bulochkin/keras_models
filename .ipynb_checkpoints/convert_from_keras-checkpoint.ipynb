{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "('Executing :', \"/Users/pavelbulochkin/banuba/keras_models/tensorflow/bazel-bin/tensorflow/python/tools//freeze_graph --input_graph=/Users/pavelbulochkin/banuba/keras_models/inference/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged_raw.pb --input_checkpoint=/Users/pavelbulochkin/banuba/keras_models/inference/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged_raw.pb.ckpt --output_graph=/Users/pavelbulochkin/banuba/keras_models/inference/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged_freezed.pb                     --output_node_names='out_layer/div' \")\n",
      "------------------------------\n",
      "('Executing :', \"/Users/pavelbulochkin/banuba/keras_models/tensorflow/bazel-bin/tensorflow/python/tools//optimize_for_inference --input=/Users/pavelbulochkin/banuba/keras_models/inference/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged_freezed.pb --output=/Users/pavelbulochkin/banuba/keras_models/inference/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged_for_inference.pb  --input_names='in_layer' --output_names='out_layer/div'\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "# import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "with K.tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver = K.tf.train.Saver(write_version=K.tf.train.SaverDef.V1)\n",
    "    \n",
    "    out_file_name = 'new_transposed_unet_YCrCb_K03D02PaRnone_o__staged'\n",
    "    keras_model_path = '/Users/pavelbulochkin/banuba/keras_models/alexander/new_transposed_unet_YCrCb_K03D02PaRnone_o__staged.hdf5'\n",
    "    \n",
    "    model = load_model(keras_model_path)\n",
    "    model.load_weights(keras_model_path)\n",
    "    \n",
    "    in_tensor = model.input.name.split(':')[0]\n",
    "    out_tensor = model.output.name.split(':')[0]\n",
    "\n",
    "    out_folder_path = os.path.join(os.getcwd() + '/inference/')\n",
    "    if not os.path.exists(out_folder_path) : \n",
    "        os.makedirs(out_folder_path)\n",
    "\n",
    "    out_file_name_raw = out_file_name +'_raw' + '.pb'\n",
    "    out_file_path_raw = os.path.join(out_folder_path, out_file_name_raw)\n",
    "    \n",
    "    out_file_name_freezed = out_file_name + '_freezed' + '.pb' \n",
    "    out_file_path_freezed = os.path.join(out_folder_path, out_file_name_freezed)\n",
    "\n",
    "    out_file_name_for_inference =  out_file_name + '_for_inference' + '.pb'\n",
    "    out_file_path_for_inference = os.path.join(out_folder_path, out_file_name_for_inference)\n",
    "\n",
    "    ckpt_out_raw_file_path = os.path.join(out_folder_path, out_file_name_raw + '.ckpt')    \n",
    "    \n",
    "    saver = K.tf.train.Saver()   \n",
    "    saver.save(sess, ckpt_out_raw_file_path)\n",
    "    \n",
    "    K.tf.train.write_graph(sess.graph.as_graph_def(), logdir=out_folder_path, name=out_file_name_raw)\n",
    "\n",
    "    \n",
    "tools_path = '/Users/pavelbulochkin/banuba/keras_models/tensorflow/bazel-bin/tensorflow/python/tools/'\n",
    "\n",
    "#--input_binary=True\n",
    "freeze_string = \"\"\"{}/freeze_graph --input_graph={} --input_checkpoint={} --output_graph={} \\\n",
    "                    --output_node_names='{}' \"\"\".format(tools_path,\n",
    "                                                    out_file_path_raw, \n",
    "                                                    ckpt_out_raw_file_path, \n",
    "                                                    out_file_path_freezed, \n",
    "                                                    out_tensor)\n",
    "\n",
    "inferece_string = \"\"\"{}/optimize_for_inference \\\n",
    "--input={} --output={}  --input_names='{}' \\\n",
    "--output_names='{}'\"\"\".format(tools_path, out_file_path_freezed, out_file_path_for_inference, in_tensor, out_tensor)\n",
    "\n",
    "#print(\"In Tensor:\", in_tensor)\n",
    "#print(\"Out Tensor:\", out_tensor)\n",
    "print('-'*30)\n",
    "print('Executing :', freeze_string)\n",
    "print('-'*30)\n",
    "print('Executing :', inferece_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'in_layer:0' shape=(?, 240, 320, 3) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'out_layer/div:0' shape=(?, 76800, 2) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
